---
title: "PKBayes2: Electric Boogaloo"
output: pdf_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, message = F, warning = F, fig.height = 4, fig.align ='center', dpi = 400, cache = F)

```

# Introduction

This document is intended to get you up to speed on some of the modelling I've done with the new data we've recieved.  I'll compare subjects between the new and old data sets on covariates important to apixaban pharmacokinetics, and will exposit model structure as best I can.  I'll summarize the new model's predictive ability on a holdout set of 100 patients from the new data and compare this predictive ability to a simple log-linear model.


```{r}
library(cmdstanr)
library(posterior)
library(tidybayes)
library(tidyverse)
library(patchwork)
library(table1)
library(lme4)
library(here)
theme_set(theme_classic())

```


# New vs. Old Data

Shown in table 1 is a comparison of the new (i.e. from the clinic) and old (i.e. from Rommel's 2018 paper) study.  In general, subjects from the new data set are older and have higher searum creatinine, indicating poorer kidney function (ostensibly from being older, perhaps indicating confounding).

The old data contains 36 patients, each sampled multiple times.  Each patient was observed at the same time post dose, allowing us to estimate a reasonably complex model.  Each patient in the new data is observed at a different time, and is observed at most once.


# The Model

Model structure is similar to our 2020 paper, with similar hyperpriors on all hyerparameters.  We estimate a random effect for each subject (even for those from the new data). Shown below is the full model structure:

$$ \log(y_{i,j}) \vert t_j, D_i, Cl_i, k_{a,i}, k_{e,i}, \delta_i \sim \mathcal{N}(C(t_j), \sigma_y)  $$
$$ C(t)  = \begin{cases} \dfrac{0.5 \times D}{Cl} \dfrac{k_e \times k_a}{k_e - k_a} \Big( \exp(k_a (t-\delta)) - \exp(k_e(t-\delta)) \Big) & t>\delta \\ 0 & \mbox{else} \end{cases}$$

$$ k_{e,i} = \alpha_i k_{a,i} $$

$$ k_{a,i} = \dfrac{\log(\alpha_i)}{t_{max,i}(\alpha_i-1)} $$

$$ \alpha_i \sim \operatorname{Logit-Normal}(\mu_\alpha, \sigma_\alpha) $$

$$ t_{max, i} \sim \operatorname{Log-Normal}(\mu_t, \sigma_t) $$

$$ Cl_i \sim \operatorname{Log-Normal}(\mu_{Cl} + \mathbf{X}\beta, \sigma_{Cl}) $$

$$ \delta_i \sim \operatorname{Beta}\Big( \dfrac{\phi}{\kappa}, \dfrac{(1-\phi)}{\kappa} \Big)$$

$$ \beta \sim \operatorname{Student-T}(0, \nu=3)  $$

We do not estimate the initial condition and assume that $y(0) = 0$. We make predictions for out of sample patients by integrating out the random effect and then taking expectations.  Note here that covariates only affect the clearance rate.  This can easily be extended so that covariates also affect average time to max concentration, or non-dimensional parameter $\alpha$.
```{r}
CHAINS = 4
SEED = 19920909
combined_data<- readRDS('../fit_data/combined_Data.RDS')
model = cmdstan_model(stan_file = '../models/big_model.stan')
fit <- model$sample(combined_data, 
                    chains = CHAINS, 
                    seed = SEED,
                    parallel_chains = 4
                    )
```

```{r}
draws = as_draws_df(fit$draws())


predictions<-draws %>% 
  spread_draws(CPRED[i]) %>% 
  mean_qi
predictions$yobs<-combined_data$test_yobs

predictions %>% 
  ggplot(aes(yobs, CPRED))+
  geom_point()+
  geom_abline()

Metrics::rmse(predictions$CPRED, predictions$yobs)
  
```


```{r}
training<-read_csv("../fit_data/train_subjects.csv") %>% filter(from_new==1)
val<-read_csv("../fit_data/test_subjects.csv")

linmod <- lm(log(yobs) ~ time + sex + age + weight + creatinine + D , data = training)

lm_predictions<-predict(linmod)
sigma = Metrics::rmse(log(training$yobs), lm_predictions)
lm_predictions<-exp(predict(linmod, newdata = val))*exp(sigma^2/2)

Metrics::rmse(lm_predictions, val$yobs)
```



```{r}
subs<-tibble(
  subjects = combined_data$subjectids,
  times = combined_data$time,
  y_obs = combined_data$yobs
) %>% 
  mutate(i = seq_along(times)) %>% 
  filter(subjects<=36)

draws %>% 
  spread_draws(C[i], n = 250) %>% 
  right_join(subs) %>% 
  ggplot()+
  geom_line(aes(times, C, group = .draw),alpha = 0.1)+
  geom_point(aes(times, y_obs), color = 'red')+
  facet_wrap(~subjects, scales = 'free_y')
```


